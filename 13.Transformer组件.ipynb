{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.Transformerç»„ä»¶\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**\n",
    "\n",
    "1. èƒ½ç”¨ä»£ç å®ç°ç¼–ç å™¨ã€è§£ç å™¨ã€ç¼–ç å™¨-è§£ç å™¨ç»“æ„\n",
    "\n",
    "2. èƒ½ç”¨ä»£ç å®ç°åŸºäºæ­£å¼¦ä½™å¼¦å‡½æ•°çš„ä½ç½®ç¼–ç \n",
    "\n",
    "3. èƒ½ç”¨ä»£ç å®ç°åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰\n",
    "\n",
    "4. èƒ½ç”¨ä»£ç å®ç°æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–(Add&Norm)ç»“æ„\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer æ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”± Vaswani ç­‰äººåœ¨ 2017 å¹´çš„è®ºæ–‡ã€ŠAttention Is All You Needã€‹ä¸­é¦–æ¬¡æå‡ºã€‚å®ƒåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸå–å¾—äº†é©å‘½æ€§çš„è¿›å±•ã€‚ä»¥ä¸‹æ˜¯ Transformer æ¨¡å‹çš„å‡ ä¸ªå…³é”®ç‰¹ç‚¹ï¼š\n",
    "\n",
    "è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰ï¼šTransformer æ‘’å¼ƒäº†ä¼ ç»Ÿçš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ç»“æ„ï¼Œä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰åºåˆ—å†…ä¸åŒä½ç½®ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚è¿™ç§æœºåˆ¶å…è®¸æ¨¡å‹åŒæ—¶å¤„ç†åºåˆ—ä¸­çš„æ‰€æœ‰å…ƒç´ ï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚\n",
    "\n",
    "å¹¶è¡Œå¤„ç†èƒ½åŠ›ï¼šç”±äºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ç‰¹æ€§ï¼ŒTransformer å¯ä»¥å¹¶è¡Œå¤„ç†åºåˆ—ä¸­çš„æ‰€æœ‰å…ƒç´ ï¼Œè¿™ä¸ä¼ ç»Ÿçš„åºåˆ—æ¨¡å‹ï¼ˆå¦‚ LSTM æˆ– GRUï¼‰ç›¸æ¯”ï¼Œå¤§å¤§æé«˜äº†è®­ç»ƒé€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformerçš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„\n",
    "\n",
    "Transformer æ¨¡å‹é€šå¸¸ç”±ç¼–ç å™¨ï¼ˆEncoderï¼‰å’Œè§£ç å™¨ï¼ˆDecoderï¼‰ç»„æˆã€‚ç¼–ç å™¨å°†è¾“å…¥åºåˆ—è½¬æ¢ä¸ºè¿ç»­çš„è¡¨ç¤ºï¼Œè€Œè§£ç å™¨åˆ™ä½¿ç”¨è¿™äº›è¡¨ç¤ºæ¥ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚\n",
    "\n",
    "å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰ï¼šTransformer é€šè¿‡å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹åŒæ—¶ä»ä¸åŒçš„è¡¨ç¤ºå­ç©ºé—´æ•æ‰ä¿¡æ¯ï¼Œå¢å¼ºäº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚\n",
    "\n",
    "ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰ï¼šç”±äº Transformer æ¨¡å‹æœ¬èº«ä¸å…·å¤‡æ•æ‰åºåˆ—é¡ºåºçš„èƒ½åŠ›ï¼Œå› æ­¤å¼•å…¥äº†ä½ç½®ç¼–ç æ¥æä¾›åºåˆ—ä¸­æ¯ä¸ªå…ƒç´ çš„ä½ç½®ä¿¡æ¯ã€‚\n",
    "\n",
    "å±‚å½’ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰å’Œæ®‹å·®è¿æ¥ï¼ˆResidual Connectionsï¼‰ï¼šTransformer ä½¿ç”¨å±‚å½’ä¸€åŒ–å’Œæ®‹å·®è¿æ¥æ¥ä¿ƒè¿›æ·±å±‚ç½‘ç»œçš„è®­ç»ƒï¼Œé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸é—®é¢˜ã€‚\n",
    "\n",
    "<img src=\"./images/transformer.jpg\" style=\"zoom:60%;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¢„è®­ç»ƒå’Œå¾®è°ƒï¼šTransformer æ¨¡å‹é€šå¸¸åœ¨å¤§é‡æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ é€šç”¨çš„è¯­è¨€è¡¨ç¤ºï¼Œç„¶åå¯ä»¥åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒã€‚\n",
    "\n",
    "å¹¿æ³›çš„åº”ç”¨ï¼šTransformer ä¸ä»…åœ¨æœºå™¨ç¿»è¯‘ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¿˜è¢«å¹¿æ³›åº”ç”¨äºå…¶ä»– NLP ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬æ‘˜è¦ã€é—®ç­”ç³»ç»Ÿã€æ–‡æœ¬åˆ†ç±»ç­‰ã€‚\n",
    "\n",
    "å˜ä½“å’Œå‘å±•ï¼šè‡ªåŸå§‹ Transformer æå‡ºä»¥æ¥ï¼Œå‡ºç°äº†è®¸å¤šæ”¹è¿›å’Œå˜ä½“ï¼Œå¦‚ BERTï¼ˆBidirectional Encoder Representations from Transformersï¼‰ã€GPTï¼ˆGenerative Pre-trained Transformerï¼‰ç­‰ï¼Œè¿™äº›æ¨¡å‹åœ¨ä¸åŒçš„ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚\n",
    "\n",
    "Transformer æ¨¡å‹çš„æå‡ºï¼Œæ ‡å¿—ç€ NLP é¢†åŸŸçš„ä¸€ä¸ªé‡è¦è½¬æŠ˜ç‚¹ï¼Œå®ƒä¸ºå¤„ç†åºåˆ—æ•°æ®æä¾›äº†ä¸€ç§å…¨æ–°çš„è§†è§’å’Œå¼ºå¤§çš„å·¥å…·ã€‚\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.ä½ç½®ç¼–ç \n",
    "\n",
    "ç”±äºTransformeræ¨¡å‹æœ¬èº«ä¸å…·æœ‰å¤„ç†åºåˆ—é¡ºåºçš„èƒ½åŠ›ï¼Œä½ç½®ç¼–ç ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿç†è§£å•è¯åœ¨å¥å­ä¸­çš„ç›¸å¯¹ä½ç½®ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸åŒé¢‘ç‡çš„æ­£å¼¦å’Œä½™å¼¦å‡½æ•°ä¸ºåºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®ç”Ÿæˆå”¯ä¸€çš„ç¼–ç ã€‚ä½ç½®ç¼–ç çš„å…¬å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "<img src=\"./images/PE.jpg\" style=\"zoom:100%;\" />\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "ğ‘ƒğ¸æ˜¯ä½ç½®ç¼–ç çŸ©é˜µã€‚\n",
    "\n",
    "posæ˜¯è¯åœ¨åºåˆ—ä¸­çš„ç»å¯¹ä½ç½®ï¼ˆä»0å¼€å§‹ï¼‰ã€‚\n",
    "\n",
    "ğ‘–æ˜¯ç»´åº¦ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰ã€‚\n",
    "\n",
    "ğ‘‘modelæ˜¯æ¨¡å‹çš„ç»´åº¦å¤§å°ã€‚\n",
    "\n",
    "å¯¹äºæ¯ä¸ªç»´åº¦ğ‘–ï¼Œä½ç½®ç¼–ç åŒ…å«ä¸¤ä¸ªå€¼ï¼šä¸€ä¸ªæ­£å¼¦å€¼å’Œä¸€ä¸ªä½™å¼¦å€¼ï¼Œåˆ†åˆ«å¯¹åº”å¶æ•°ç´¢å¼•å’Œå¥‡æ•°ç´¢å¼•ã€‚\n",
    "\n",
    "ä½ç½®ç¼–ç çš„ç›®çš„æ˜¯ç»™æ¨¡å‹æä¾›æ¯ä¸ªè¯åœ¨åºåˆ—ä¸­çš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼Œè¿™æ ·æ¨¡å‹å°±å¯ä»¥åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥ç†è§£è¯ä¸è¯ä¹‹é—´çš„å…³ç³»ã€‚ä½ç½®ç¼–ç é€šå¸¸è¢«æ·»åŠ åˆ°è¯åµŒå…¥ï¼ˆWord Embeddingsï¼‰ä¸­ï¼Œç„¶åä¸€èµ·è¾“å…¥åˆ°Transformeræ¨¡å‹ä¸­ã€‚\n",
    "\n",
    "Transformerçš„ä½ç½®ç¼–ç é€‰æ‹©ä¸‰è§’å‡½æ•°çš„å®˜æ–¹è§£é‡Šæ˜¯ï¼š\n",
    "\n",
    "ä½ç½®ç¼–ç çš„æ¯ä¸ªç»´åº¦éƒ½å¯¹åº”äºä¸€ä¸ªæ­£å¼¦æ›²çº¿ã€‚æ³¢é•¿å½¢æˆä¸€ä¸ªä»2Ï€åˆ°10000Â·2Ï€çš„å‡ ä½•è½¨è¿¹ã€‚æˆ‘ä»¬ä¹‹æ‰€ä»¥é€‰æ‹©è¿™ä¸ªå‡½æ•°ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬å‡è®¾å®ƒå¯ä»¥è®©æ¨¡å‹å¾ˆå®¹æ˜“åœ°é€šè¿‡ç›¸å¯¹ä½ç½®è¿›è¡Œå­¦ä¹ ï¼Œå› ä¸ºå¯¹äºä»»ä½•å›ºå®šçš„åç§»é‡k,PEpos+kéƒ½å¯ä»¥è¡¨ç¤ºä¸ºPEposçš„çº¿æ€§å‡½æ•°ã€‚\n",
    "\n",
    "ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªç»´åº¦éƒ½æ˜¯æ³¢é•¿ä¸åŒçš„æ­£å¼¦æ³¢ï¼Œæ³¢é•¿èŒƒå›´æ˜¯2Ï€åˆ°10000Â·2Ï€ï¼Œé€‰ç”¨10000è¿™ä¸ªæ¯”è¾ƒå¤§çš„æ•°æ˜¯å› ä¸ºä¸‰è§’å‡½æ•°å¼æœ‰å‘¨æœŸçš„ï¼Œåœ¨è¿™ä¸ªèŒƒå›´åŸºæœ¬ä¸Šï¼Œå°±ä¸ä¼šå‡ºç°æ³¢é•¿ä¸€æ ·çš„æƒ…å†µäº†ã€‚ç„¶åè°·æ­Œçš„ç§‘å­¦å®¶ä»¬ä¸ºäº†è®©PEå€¼çš„å‘¨æœŸæ›´é•¿ï¼Œè¿˜äº¤æ›¿ä½¿ç”¨sin/cosæ¥è®¡ç®—PEçš„å€¼ï¼Œå°±å¾—åˆ°äº†æœ€ç»ˆçš„å…¬å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½ç½®ç¼–ç \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # åˆå§‹åŒ–ä¸€ä¸ªå…¨0çš„ä½ç½®ç¼–ç çŸ©é˜µï¼Œå¤§å°ä¸º(1, max_len, num_hiddens)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        # è®¡ç®—ä½ç½®ç¼–ç \n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1) / torch.pow(\n",
    "            10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        # ä½¿ç”¨æ­£å¼¦å‡½æ•°ä¸º0,2,4,...ç»´åº¦çš„ä½ç½®ä¸Šå¡«å……ä½ç½®ç¼–ç \n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        # ä½¿ç”¨ä½™å¼¦å‡½æ•°ä¸º1,3,5,...ç»´åº¦çš„ä½ç½®ä¸Šå¡«å……ä½ç½®ç¼–ç \n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # å°†ä½ç½®ç¼–ç åŠ åˆ°è¾“å…¥Xä¸Š\n",
    "        X += self.P[:, :X.shape[1], :].to(X.device)\n",
    "        \n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–(Add&Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–(Add&Norm)\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "        \n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.ç¼–ç å™¨-è§£ç å™¨ç»“æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 ç¼–ç å™¨\n",
    "\n",
    "åœ¨ç¼–ç å™¨æ¥å£ä¸­ï¼Œæˆ‘ä»¬åªæŒ‡å®šé•¿åº¦å¯å˜çš„åºåˆ—ä½œä¸ºç¼–ç å™¨çš„è¾“å…¥Xã€‚ä»»ä½•ç»§æ‰¿è¿™ä¸ªEncoderåŸºç±»çš„æ¨¡å‹å°†å®Œæˆä»£ç å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"The base encoder interface for the encoder--decoder architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 è§£ç å™¨\n",
    "\n",
    "åœ¨ä¸‹é¢çš„è§£ç å™¨æ¥å£ä¸­ï¼Œæˆ‘ä»¬æ–°å¢ä¸€ä¸ªinit_stateå‡½æ•°ï¼Œç”¨äºå°†ç¼–ç å™¨çš„è¾“å‡ºï¼ˆenc_outputsï¼‰è½¬æ¢ä¸ºç¼–ç åçš„çŠ¶æ€ã€‚ä¸ºäº†é€ä¸ªåœ°ç”Ÿæˆé•¿åº¦å¯å˜çš„è¯å…ƒåºåˆ—ï¼Œè§£ç å™¨åœ¨æ¯ä¸ªæ—¶é—´æ­¥éƒ½ä¼šå°†è¾“å…¥å’Œç¼–ç åçš„çŠ¶æ€æ˜ å°„æˆå½“å‰æ—¶é—´æ­¥çš„è¾“å‡ºè¯å…ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        # åˆå§‹åŒ–æ–¹æ³•ï¼Œåœ¨è¿™é‡Œå¯ä»¥åˆå§‹åŒ–è§£ç å™¨çš„å‚æ•°å’Œå±‚\n",
    "        super().__init__()\n",
    "\n",
    "    # init_stateæ–¹æ³•ç”¨äºåˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€ã€‚\n",
    "    # è¿™ä¸ªæ–¹æ³•åº”è¯¥åœ¨æ¯ä¸ªå…·ä½“çš„è§£ç å™¨ç±»ä¸­è¢«å®ç°ï¼ˆoverrideï¼‰ã€‚\n",
    "    # enc_all_outputså‚æ•°ä»£è¡¨ç¼–ç å™¨çš„æ‰€æœ‰è¾“å‡ºï¼Œå¯ä»¥ç”¨äºåˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€ã€‚\n",
    "    # *argså…è®¸ä¼ å…¥é¢å¤–çš„å‚æ•°ï¼Œè¿™æä¾›äº†çµæ´»æ€§ï¼Œä»¥é€‚åº”ä¸åŒçš„è§£ç å™¨å®ç°ã€‚\n",
    "    def init_state(self, enc_all_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Xä»£è¡¨è¾“å…¥åˆ°è§£ç å™¨çš„åºåˆ—æ•°æ®ã€‚\n",
    "    # stateä»£è¡¨è§£ç å™¨çš„çŠ¶æ€ï¼Œå®ƒå¯èƒ½åŒ…å«ç¼–ç å™¨çš„è¾“å‡ºã€éšè—çŠ¶æ€ç­‰ä¿¡æ¯ã€‚\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 ç¼–ç å™¨-è§£ç å™¨ç»“æ„\n",
    "\n",
    "ç¼–ç å™¨â€è§£ç å™¨ç»“æ„åŒ…å«äº†ä¸€ä¸ªç¼–ç å™¨å’Œä¸€ä¸ªè§£ç å™¨ï¼Œå¹¶ä¸”è¿˜æ‹¥æœ‰å¯é€‰çš„é¢å¤–çš„å‚æ•°ã€‚åœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œç¼–ç å™¨çš„è¾“å‡ºç”¨äºç”Ÿæˆç¼–ç çŠ¶æ€ï¼Œè¿™ä¸ªçŠ¶æ€åˆè¢«è§£ç å™¨ä½œä¸ºå…¶è¾“å…¥çš„ä¸€éƒ¨åˆ†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºç±»\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
